Bootstrap: docker
From: nvidia/cuda:12.9.0-cudnn-devel-ubuntu22.04

%post
    apt-get update && apt-get install -y \
        git \
        curl \
        build-essential \
        python3-dev \
        python3-pip

    # Install Ollama
    curl -L https://ollama.com/download/ollama-linux-amd64.tgz -o ollama-linux-amd64.tgz
    tar -C /usr -xzf ollama-linux-amd64.tgz


    # Set up working directory
    mkdir -p /lms-api-server
    cd /lms-api-server

    # Upgrade pip and install dependencies
    pip install --upgrade pip
    pip install --no-cache-dir -r /lms-api-server/requirements.txt --force

%files
    ../lms-api-server/app /lms-api-server/app
    ../lms-api-server/requirements.txt /lms-api-server/requirements.txt

%environment
    export PYTHONUNBUFFERED=1
    export WORKDIR=/lms-api-server

%runscript
    cd /lms-api-server
    exec uvicorn app.main:app --host 0.0.0.0 --port 9394